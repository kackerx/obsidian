# 数据库

## 索引
--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title: 亮点1 - 为什么使用B+树

- 1, 二叉搜索树有平衡性问题, 极端情况下会退化成链表, 平衡树二叉树有再平衡问题, 高度更高性能更差
- 2, 跳表平衡性差, 需要更多的内存, 空间换时间
- 3, B树数据存在全部节点, 对范围查询不友好, 占内存, 就会需要磁盘IO
~~~

</br>

~~~ad-grey
title: 亮点2 - 为什么不使用索引

- 有时使用!=, like时
- 隐式的类型转换
- 函数, 数学运算等
- 字段区分度不大
- 数据量太小, mysql优化器觉得不如全表扫描
- 不得已可以使用<mark class="hltr-blue">force index</mark>
- 使用NULL, mysql也是会尽量使用索引的, 唯一索引是可以多列都为NULL的, 比较差的实践
~~~

--- column-break ---



--- end-multi-column

## 优化
--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title: 优化主题

- 硬件优化: 内存, 机器性能
- 操作系统优化: 某些设置
- 服务器/引擎优化: 调整事务隔离级别或者Innodb刷盘时机等的参数, buffer_pool_size等
- sql优化: 减少磁盘IO(避免全表扫描, 回表, 索引覆盖, 索引下推等), 煎炒内存cpu消耗(主要是尽可能减少排序, 分组, 去重等)
~~~
![[Pasted image 20240905105124.png|577]]

--- column-break ---

~~~ad-grey
title: SQL优化

- 对于sql优化其实就是在『EXPLAIN』查看和尝试之间循环往复
- system > const > eq_ref > ref > range > index > all
~~~
![[Pasted image 20240905105453.png|577]]

--- column-break ---

~~~ad-success
title: 索引列的选择

- 外键, 常用与关联, 过滤数据
- 频繁where的列, 避免全表扫描
- 频繁order by的, 避免文件排序
- 区分度较高的列
~~~

</br>

~~~ad-danger
title: 表定义变更

- 『数据库ddl变更会加表锁, 直到修改完成』 
- 1, 停机变更
- 2, 业务低峰期变更
- 3, 创建新表进行迁移
~~~
![[Pasted image 20240905110017.png|577]]

--- end-multi-column
### 优化案例
--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title: 覆盖索引

- select 具体的字段, 这些常查的字段联合索引
~~~

</br>

~~~ad-grey
title: 优化order by

- 列表通常对某个时间进行排序, 那么排序列加入索引
- 比如经常的使用`where uid=1 order by update_at`, 这种情况<uid, updated_at>
- 所有排序场景, 『都尽量利用索引还排序』, 减轻数据库压力, 如order by, distinct
~~~

--- column-break ---

~~~ad-success
title: 优化count

- `count(*)`其实是一条条的去循环计数, 因为MVCC的存在不可能精确记录条数
- 要么使用explain的预估条数
- 使用redis记录, 或者直接一个额外的计数表
~~~

</br>

~~~ad-warn
title: 索引提示优化

- mysql的优化器可能使用了错误的索引或者没使用索引
- 那么考虑使用force index, 但本身不是好的实践
~~~

--- column-break ---

~~~ad-danger
title: where替换having

- 尽量在where这里第一次过滤
- from > on > join > where > groupby > having > select > distinct > orderby > limit
~~~

</br>

~~~ad-ex
title: 优化分页上的偏移量

- 使用小的偏移量
- 如果数据较多, limit 5000, 50, 那么这里丢弃前5000个, 不如加条件`where id > max_id`, 大于上一批最大ID保证limit偏移量是0
~~~
--- end-multi-column
## 锁

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title: 亮点1 - 缺索引

- 锁是在索引的维度上加的, 如果没有索引可能会直接锁表
- 
~~~

--- column-break ---

~~~ad-grey
title: 亮点2 - 临建锁引发的死锁

- ID最大是78, 那么插入79, 和80都去select for update就会进入死锁
- 锁产生的原因是两个for update都占用了(78, max], 后边insert时都等对方的锁
- 解决方案: 
	- 先插入默认数据, 没有数据插入成功执行不存在的逻辑, 此时数据库有该ID所以执行的是行锁也不会是gap锁
	- 调整隔离级别RC, 锁是针对RR的
	- 使用乐观锁代替悲观锁, 引申到MVCC
~~~
![[Pasted image 20240905114903.png|577]]

--- column-break ---

~~~ad-success
title: 亮点3 - 乐观代替悲观

- 其实也是用version或者updated_at等的CAS操作
~~~

--- end-multi-column
## MVCC

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

df

--- column-break ---

df

--- end-multi-column

## 日志

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title: undo log

- 回滚日志, 后悔药, 事务回滚, 记录的是当前事务操作的逆操作
- Insert --> delete
- Delete --> insert
- Update --> 没有更新主键记录的就是主键和更新前的原值, 反之则是DELETE + INSERT
~~~

--- column-break ---

~~~ad-grey
title: redo log

- Innodb是读写的内存中BF(Buffer Pool), 防止没刷盘就崩溃所以需要日志
- redolog采用WAL, 同时是顺序读写, 异步刷盘, 高性能
- 0/1/2: 每秒刷盘, 每提交刷盘, 每提交刷page cache
- redo log buffer快满了也会刷盘, 通常是一半
~~~
![[Pasted image 20240905142028.png|577]]

--- column-break ---

~~~ad-success
title: binlog

- 逻辑日志, 和redo log构成二阶段提交
- redo log影响主库数据(crash后恢复 ), binlog影响从库数据(主从同步), 所以那么是一定要通过二阶段提交来保证一致性的
~~~

--- end-multi-column
### 亮点方案
--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 2
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title: 写入语义

- 要明确写入语义, 中间件的写入语义可能是写入自身日志或者缓冲区, 写入page cache, 持久化磁盘三种情况
- 分布式环境下写入语义更加复杂, 要考虑是不是只写主节点, 还是在从节点同步后才ack, 或者是大多数节点写入后ack, 比如kafka的acks, 比如redis的AOF刷盘时机
~~~

--- column-break ---

~~~ad-grey
title: 调整刷盘时机

- 对于数据绝对不能丢的, 一致性要求高的, `sync_binlog = 1; innodb_flush_log_at_trx_commit = 1;`
- 对于性能优先的, redolog可以设置成2, `sync_binlog = 100;`即100个事务才刷盘
~~~

--- end-multi-column

## 数据迁移

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-tips
title: 场景

- 重构老系统: 使用新的表结构来存储数据
- 单库拆分分库分表, 分库分表扩容
- 大表修改表结构定义, 如加索引会锁表, 则对应新表
~~~

</br>

~~~ad-primary
title: innodb_autoinc_lock_mode

- 控制自增主键生成策略的参数
- 0, 表自增锁, INSERT语句之后释放
- 1, 表自增锁, 普通的INSERT INTO是申请了主键就释放, 如果是INSERT SELECT则无法确定插入多少行所以整个INSERT执行完释放
- 2, 表自增锁, 全部申请了主键立即释放
~~~
![[Pasted image 20240905145741.png|577]]

--- column-break ---

~~~ad-grey
title: 数据迁移基本步骤

- 创建目标表, 源表数据初始化目标表
- 执行一次校验并且修复数据, 此时源表数据修复目标表数据
- 业务代码开启双写, 读源表, 先写源表, 数据以源表为准
- 开启增量校验和数据修复, 保持一段时间
- 切换双写顺序, 读目标表, 先写目标表, 数据以目标表为准
- 继续保持增量校验和数据修复
- 切换为目标表单写, 只读写目标表
~~~
![[Pasted image 20240905145055.png|577]]

--- column-break ---

~~~ad-success
title: 初始化目标数据

- 我们可以使用历史备份数据, 或者<mark class="hltr-blue">mysqldump</mark> 免费开源的导入和导出
- 优化导出速度: 开启`extended-insert`将多行合并为一个insert语句
- 优化导入速度: 1, 关闭唯一性检查和外键检查源表已经保证, 2, 关闭binlog, 3, 调整redolog刷盘时机为0
~~~

</br>

~~~ad-warn
title: 第一次校验和修复

- 比如使用`update_time`字段, 根据更新时间修复的时候用源表数据覆盖目标表数据
~~~

</br>

~~~ad-danger
title: 业务代码双写, 源表为准

- 这里要么采用『侵入式方案』即业务代码里进行双插入, 代价高, 容易漏, 要测试, 不建议
- 『非侵入式』一般和ORM中间件相关, 1, 提供AOP方案, 2, 数据库操作抽象, 这数据库的这个接口的每个操作中进行处理
- 不管哪个方案, 如果要不停机迁移, 就需要确保双写可以在运行时切换, 可以配置为<mark class="hltr-blue">单写源表</mark>, <mark class="hltr-cyan">单写目标表</mark>, <mark class="hltr-grey">先写某个表</mark>等
- 比如GORM的『Hook』功能
- 对于双写过程中可能问到的<mark class="hltr-blue">数据一致性问题</mark>, <mark class="hltr-cyan">主键问题</mark>
	- 写入源表成功, 目标表失败, 不管, 等待后续的数据校验和修复机制
	- 对于主键, 写入目标表也要写入源表的主键

~~~
![[Pasted image 20240905151957.png|577]]
--- end-multi-column
### 方案步骤
--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-danger
title: 增量校验和数据修复

- 一边保持双写, 一边校验最新修改数据和修复
- 1, 利用更新时间戳, 2, 利用binlog优先考虑
~~~

</br>

~~~ad-ex
title: 1 - 更新时间戳

- 前提所有的表都有更新时间戳并且软删时可以使用根据更新时间戳来校验和修复
- 但是如果不是软删则需要再源表修复目标表之后, 反过来校验一遍
~~~
![[Pasted image 20240905154500.png|577]]

![[Pasted image 20240905154837.png|577]]

--- column-break ---

~~~ad-inf
title: 可能遇到主从同步延迟

- 校验和修复读的都是从库时, 可能遇到目标表主从延迟, 或者源表主从延迟
- 都读主库, 缺点是压力大, 『双重校验』, 第一校验读从库, 发现不一致就去读主库再次校验, 以主库的为准
~~~
![[Pasted image 20240905155220.png|577]]

</br>

~~~ad-note
title: 2 - binlog

- 『基于行格式的binlog』, <mark class="hltr-blue">binlog触发</mark>
- 校验和修复采用监听binlog的方案, 收到binlog后拿主键去目标表查询和binlog是否一致, 不一致用binlog的主键去源表查询到后覆盖目标表
~~~
![[Pasted image 20240905155751.png|577]]

--- column-break ---

~~~ad-primary
title: 切换双写顺序

- 双写时不直接切换目标表单写, 没法回滚
- 中间引入双写先写目标表, 业务读目标表, 这样出问题可以回滚, 因为源表也写了
~~~
![[Pasted image 20240905160108.png|577]]

~~~ad-grey
title: 保持增量校验和修复

- 这一步是以主表也就是目标表为准
~~~
--- end-multi-column

## 分库分表

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-tips
title: 分库分表键 & 主键

- 主键是用作唯一性的, 可以不包含业务逻辑, 递增
- 分库分表键则是用于确定数据分布在哪个表哪个库, 比如用用户ID来分, 用创建时间来分等
~~~

</br>

~~~ad-primary
title: UUID

- 简单粗暴的UUID, 也是基本和常见的, 有明显的弊端
- 1, 过长, 2, UUID不是自增的
~~~

</br>

~~~ad-grey
title: 页分裂

- 因为不是递增, 所以影响插入性能, 会引起频繁的页分裂, 糟糕情况下可能引起连锁反应, 整颗索引树都有影响
- 递增主键另一个好处是『磁盘顺序读』, 主键相近的记录磁盘位置也是相近的范围查询时更充分利用磁盘的顺序读
- 页分裂后虽然逻辑上123, 和567是相邻的页, 但是真实磁盘存储可能离得很远
~~~

--- column-break ---

~~~ad-success
title: 数据库自增

- 设置了『步长』的自增, 如第一个表是1, 11, 21, 第二个表是2, 12, 22
- 非全局递增但是表内部是自增的, 应用层不需要太关注
~~~

--- column-break ---

~~~ad-warn
title: 雪花算法

- 64位, 1保留, 41时间戳, 10机器ID, 12序号
- 雪花算法可以算一种思想, 借助时间戳和分段, 自由切个ID的不同比特位赋予其不同的含义, 灵活设计自己的ID算法
- 每个分段都可以根据业务规模来控制长度, 机器ID可以引入一些特定的业务含义等
~~~
![[Pasted image 20240905171831.png|577]]

</br>

~~~ad-warn
title: 序列号耗尽 & 数据堆积

- 12bit不够的话, 可靠增加长度比如使用96位, 或者耗尽就让业务等一下1ms的时间戳
- 关于数据堆积: 如果分库分表是按照ID除以32取余, 如果业务低频可能有很多ID尾号都是1, 2, 3是不是所有的数据都分到一张表中
	- 1, 某一时刻使用随机数为起点, 而不是每次从0开始计数
	- 2, 还有策略是从上一时刻序列号开始增长
~~~
--- end-multi-column
### 亮点方案
--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title: 主键内嵌分库分表键

- 分库分表键和主键大多时候不是同一个, 比如C端订单分库分表, 买家ID来进行分库分表, 但是同时一些根据根据订单code和主键来查询详情的情况
- 借鉴雪花算法设计, 主键生成策略和分库分表键结合, 比如第一段时间戳, 第二段是买家ID后四位, 第三段随机数
- 在我们只有ID要去查的时候就可以根据ID中取出买家ID找到具体的表和库, 即是分库分表键放到生成ID的分段中去
- 这个方案可能得坑, 『没法保证全局递增』, 『保证独一无二』
~~~
![[Pasted image 20240905175517.png|577]]

--- column-break ---

~~~ad-grey
title: 问题相关

- 没法保证全局递增: 因为用户ID更小的用户晚创建的单子序号是小于早创建但是用户ID大的主键的, 又或者同一用户同一时刻的多个单子, 随机数大小问题, 但是因为有时间戳在前, 这个概率还是很小的
- 独一无二: 同一用户同一时刻产出多个单子还随机到了重复数字, 概率更小
~~~

--- column-break ---

~~~ad-warn
title: 优化思路

- 批量取: 跟发号器打交道不是只获取一个, 批量获取一批后自己消化, 缺点是破坏递增趋势, 服务A和服务B分别取100使用时
- 提前取: 提前获取
- singlefight取: 单飞
- 局部分发: 从全局变量获取有加锁竞争问题
~~~

--- end-multi-column
### 分页查询
--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title: 分库分表键一般做法

- 哈希分库分表: 比如UID%8
- 范围分库分表: 比如[0-1000]在第一张表, 常见的按照月份分表, 按照创建时间分表
- 中间表: 引入中间表记录主键倒目标表的映射
~~~
![[Pasted image 20240905182540.png|577]]

</br>

~~~ad-grey
title: 分库分表中间件形态

- SDK: 语言强绑定
- Proxy: 独立部署的中间件, 解耦业务和db, 但是有性能问题单点问题
- Sidecar: 每个节点部署一个, 解决了性能和单点问题但是不成熟产品
~~~

--- column-break ---

~~~ad-success
title: 1 - 全局分页

- 符合查询条件的结果可能在不同的分表中, 那么全局分页的做法就是
- `limit 4 offset 2` --> `limit 6 offset 0`, 即`limit x+y offset 0`
- 查询全部表后在内存中排序
- 该方案性能不好, 网络, 内存有浪费, 不过可以通过归并排序来缓解, 因为每一个表返回的都是有序的, 可以逐条读取, 没必要全放内存
~~~
![[Pasted image 20240906103236.png|577]]

--- column-break ---

~~~ad-warn
title: 平均分页

- 对顺序和精度要求不严格的场景, 如果值要求足够的数量那就平均每张表获取一部分
~~~

</br>

~~~ad-danger
title: 禁用跨页查询

- 目前较好的做法是禁用跨页查询, 每次查询条件加上上一次的极值(最大或最小)
- `order by ID limit 10 offset 0; where id > max_id order by ID limit 10 offset 0`
- 根据order by, 升序用最大值, 降序用最小值, 手机APP下拉刷新是好用的方案
~~~

</br>

~~~ad-ex
title: CQRS

- 同步到ES等NoSQL等分布式数据库去做查询
~~~
--- end-multi-column
### 亮点方案
--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 2
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title: 二次查询

- 首次查询拿到最小值, 二次查询确认最小值的全局偏移量, 二次查询的结果根据最小值取到符合偏移量的数据
~~~

--- column-break ---

~~~ad-grey
title: 引入中间表用于排序查询

- 加上排序相关的列, 缺点是只能使用该表的这个列, 还有维护中间表的数据一致性问题(Canal binlog)
~~~
![[Pasted image 20240906151031.png|577]]

--- end-multi-column
### 分库分表 & 分布式事务
--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title: 二阶段提交

- 准备阶段执行但不提交, 由TM来告知下一步是commit还是rollback
- 缺点: 执行过程中节点都是阻塞等待TM的, TM单点故障问题
- 第二阶段TM发送commit时RM没收到, TM一直重试
- 但是如果收到了commit但是提交之前RM宕机, 此时等恢复后查看本地日志找到Commit命令的话再使用Redo信息来提交事务
~~~
![[Pasted image 20240906153117.png|577]]

</br>

~~~ad-primary
title: 三阶段提交

- 三阶段其实在二阶段基础上加了第一阶段(CanCommit): TM询问各RM能不能执行事务, RM检查资源
- 否则每个节点都费力去执行了事务但不提交, 某个节点执行不了那么还要全部回滚
- 比较复杂不推荐使用
~~~
![[Pasted image 20240906153500.png|577]]

</br>

~~~ad-primary
title: XA

- XA遵循二阶段提交协议, 具象化的标准, 定义了TM和RM之间的接口
- XA可以认为是满足ACID的, 或者说更加接近ACID
~~~

--- column-break ---

~~~ad-grey
title: TCC

- TCC可以看做是二阶段提交的另一种实现, 不需要阻塞事务等待
- 比如说Try是插入数据但是状态是初始化不可用, Commit则更新成可用, Cancel则是删除
- TCC的每个阶段都是一个完整的本地事务
- 
~~~

</br>

~~~ad-grey
title: TCC容错

- 容错很多时候就是重试, 重试失败人工介入, 或引入自动故障处理机制, 后续尝试修复数据
- T阶段出错没问题, 直接失败失败, 如果Confirm阶段失败会出现一致性问题, 部分事务成功部分失败
- 此时就是重试, 重试一直失败做好监控和告警
- 还有方案1, 异步比较修复数据, 对账程序
- 方案2, 读取时发现不一致的话丢弃数据同时触发修复逻辑
~~~
![[Pasted image 20240906155747.png|577]]

--- column-break ---

~~~ad-success
title: SAGA

- 业务分成一个个步骤, 某一个步骤失败, <mark class="hltr-blue">反向补偿</mark>前面步骤, <mark class="hltr-cyan">注意补偿不是回滚, 补偿是额外的擦除操作</mark>
- 相比TCC, SAGA没有第一步的预留资源, 补偿动作实现起来可能麻烦, 但是同样因为没预留资源所以不担心资源释放
- 如发邮件, TCC下==Try(草稿)==, ==发送(Confirm)==, 撤销就==删除草稿(Cancel)==
- 而Saga就是直接发送, 撤销是再发一份邮件说明撤销
~~~
![[Pasted image 20240906161147.png|577]]

</br>

~~~ad-warn
title: AT

- 由SAGA引出AT, AT模式你可以看做SAGA的简化形态
- 即AT指操作多个数据库, 分布式事务中间件帮你生成这些db操作的反向操作
- 类似<mark class="hltr-blue">undo log</mark>, 比如INSERT生成DELETE, UPDATE生成对应的UPDATE
- 同样的容错处理机制
~~~

</br>

~~~ad-danger
title: 禁用跨库事务

- 从规范上禁用跨库事务, 改造业务代码, 避免跨库
~~~
--- end-multi-column
### 亮点方案
--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title: 延迟事务

- 分库分表中间件严重, Begin无法预测在哪些数据库上开启事务, 如果是全部库开启事务会浪费资源
- 所以有了延迟事务, Begin时分库分表中间件并没有真的开启事务, 而是直到执行SQL时在目标数据库上开启事务
- 部分失败的话重试加人工介入, 或者高级方案<mark class="hltr-blue">自动故障处理机制</mark>
~~~

--- column-break ---

~~~ad-grey
title: 自动故障处理机制

- 事务里部分库的提交或者回滚失败, 触发告警, 自动故障处理机制根据告警信息来修复数据
- 修复数据分为用已经提交的数据库的数据来修复没有提交成功的, 或者用没有提交成功的数据库的数据来还原已经提交的, 具体分析
~~~
![[Pasted image 20240906163734.png|577]]

--- column-break ---

~~~ad-success
title: ov - 关于容错

- 监控+告警+人工介入
- 读请求+数据修复
- 监控+告警+自动故障处理机制
~~~

--- end-multi-column

### 分库分表键选择和查询
--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-tips
title: 分库分表键 & 主键

- 主键是用作唯一性的, 可以不包含业务逻辑, 递增
- 分库分表键则是用于确定数据分布在哪个表哪个库, 比如用用户ID来分, 用创建时间来分等
~~~

</br>

~~~ad-tips
title: 分库分表键选择

- 业务字段有多个如何选择? - 根据查询来选择
- 例如订单里常见的事按照买家ID来分库分表, 买家查询自己订单是主要的场景且服务体验更重要, 买家ID收益最大
- 或者常用的, 主键, 外键, 索引列, 范围的话日期列
~~~

</br>

~~~ad-bug
title: 分库分表的查询问题

- 订单表是按照买家ID来分库分表, 那么卖家如何查询怎么办?
- 没有按照分库分表键来筛选数据的查询, 需要额外的手段支持的
- 1, 主流的<mark class="hltr-blue">引入中间表</mark>
- 2, <mark class="hltr-cyan">二次分库分表</mark>
- 3, 其他中间件
- 4, 广播策略
- 5, 主键生成策略特殊(内嵌分库分表键)
~~~

</br>

~~~ad-note
title: ov - 数据同步问题

- 中间表, 二次分库分表, 其他中间件等方案都面临数据同步一致性的问题
- 要么双写, 要么canal订阅binlog
- 两种方案重试失败后, 加上异步修复程序尝试修复, 最兜底的人工介入
~~~

</br>

~~~ad-ex
title: ov - 亮点方案

- 满足不同情况的查询需求, 综合使用三种方案
- 1, 对于卖家查询复制一份数据, 按照卖家ID分库分表, 也就是引入二次分库分表
- 2, 对于复杂的统计分析, 使用ES存储部分字段
- 3, 引入中间表, 如商品ID和订单ID映射, 同时订单ID内嵌分库分表键
~~~

--- column-break ---

~~~ad-primary
title: 主键生成策略

- 主键内嵌分库分表键那么我们就可以知道该去哪个库表查
- 解决只有主键时的查询, 主键生成策略不支持的话其他方案
~~~
![[Pasted image 20240906170145.png|577]]

</br>

~~~ad-grey
title: 引入中间表

- 如图或者考虑买家ID换成目标库目标表
- 中间表找到卖家ID的订单ID和买家ID, 根据买家ID或者订单号找到订单数据
- 1, 可以结合前一条主键生成策略内嵌买家ID中间表少一列
- 2, 写入中间表有性能瓶颈所以尽量少的列, 不要频繁更新的列, ID类的可以
- 3, 不灵活如果要新增商品查订单, 那么可能要新增商品ID列, 但是中间表是大表, 修改结构很危险, 新增中间表又会增加维护成本
~~~
![[Pasted image 20240906171213.png|577]]

--- column-break ---

~~~ad-success
title: 二次分库分表

- 比方说根据买家ID来分库分表订单, 那么同时根据卖家ID再次分库分表订单
- 减轻存储压力: 此时复制的卖家分表可以留些必要的字段减少空间占用, 有缺少的字段可以在卖家库拿到ID等的后再回表
- 减轻查询压力: 如二级索引以及覆盖索引, 减轻回表查询压力
- 
~~~
![[Pasted image 20240906171829.png|577]]

</br>

~~~ad-warn
title: 其他中间件

- 复杂多样的查询直接使用ES
- 可以只同步给es搜索相关的字段, 减轻es压力
~~~

</br>

~~~ad-danger
title: 广播

- 兜底方案是全部表查询后内存汇总
- 对数据库压力大, 浪费资源, 某些查询还涉及锁
~~~
![[Pasted image 20240906172252.png|577]]
--- end-multi-column
### 分库分表容量预估
--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title: 分区表

- Mysql分区表是表底层的组织方式
- 把一张表分成几块, 每块存在磁盘一个地方
- 典型的按月分区
~~~
![[Pasted image 20240906182224.png|577]]

</br>

~~~ad-ask
title: 为什么分库分表?

- 『逼不得已, 性能瓶颈, 无法优化』
- 1, 对于写瓶颈, 分区表可以缓解, 读写分离没太大效果在频繁的增删改操作下
- 2, 对于硬件瓶颈, 分区表解决不了, 读写分离也没效果, 比如写操作引发的带宽问题
- 所以就是写性能瓶颈了
~~~

--- column-break ---

~~~ad-list
title:  

- 
~~~

--- end-multi-column
## 数据库高可用, 高性能
--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-list
title:  

- 查询优化(索引相关)
- 参数调优
- 读写分离
- 分库分表
~~~

</br>

~~~ad-one
title: 参数调优

- `innodb_buffer_pool_size`: 除下图外, 还有个重要的缓冲池的大小, 尽可能调大, 内存的%70左右, 物理内存不足会触发<mark class="hltr-blue">swap</mark>
- `innodb_buffer_pool_instances`: 如果上面的size参数比较大了比如超过8g, 那么单实例并发竞争会厉害, 可以设置多个缓存池实例
- 
~~~
![[Pasted image 20240909150619.png|577]]

--- column-break ---

~~~ad-two
title: 读写分离

- 准备一个从库
- 改造业务, 允许业务动态切换读主库还是读从库
- 切换到读从库, 随时回滚

~~~

</br>

~~~ad-two
title: 问题

- 但是要注意, 『主从延迟』问题, 最终一致性
- 同时, 可以用<mark class="hltr-blue">KeepAlived</mark>来做一个简单的自动主从切换的机制, 而不是手动处理, 或者说云服务本身提供自动切换功能
~~~

--- column-break ---

~~~ad-three
title: 分库分表

- 为什么要分库分表
- 中间件选型的优缺点, ShardingSphere
- 容量规划
- 数据迁移
- 分库分表键选择
- 主键生成策略
- 分库分表的事务问题
- 特殊查询, 比如分页查询
- 主要负责的部分
~~~

--- end-multi-column
