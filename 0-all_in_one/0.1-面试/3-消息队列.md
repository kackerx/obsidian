# 消息队列

## 场景

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-tips
title: 常见场景

- 异步, 削峰, 解耦, 事件驱动架构
- 秒杀场景
- 超时取消
- 事件驱动架构
~~~

</br>

~~~ad-one
title: 秒杀场景

- <mark class="hltr-blue">轻重之分</mark>
- 常见的秒杀场景中, 把操作分为轻重之分, 轻量级服务做请求校验, 库存扣减, 比如操作redis等后丢到mq
- 订单服务消费执行比较重的逻辑
~~~
![[Pasted image 20240909154425.png|577]]

--- column-break ---

~~~ad-two
title: 超时取消

- 延时消息, 同时要注意那一刻用户支付和消费超时消息时的并发处理问题
- 考虑分布式锁, 乐观锁, for update防止并发操作
~~~
![[Pasted image 20240909154818.png|577]]

</br>

~~~ad-ask
title: 为什么要使用消息队列

- 性能差: 通知下游如果是同步调用, 而生产消息是很快的
- 扩展性: 新的下游只需要订阅topic而不需要去改代码
- 可用性: 消息发送成功可以认为是成功了, 没有同步的部分成功部分失败的问题, 容错也更好
~~~

--- column-break ---

~~~ad-three
title: 事件驱动

- 低耦合, 可扩展, 高可用
- 适合用来解决一些『复杂, 步骤繁多, 流程冗长』的业务问题
- 事件驱动来实现SAGA的分布式事务解决方案
- 每个步骤结束后发送一个或多个成功或者失败的事件, 由消费方去决定要不要补偿(只是补偿而不是回滚, 因为已经提交过了)
~~~
![[Pasted image 20240909155836.png|577]]

--- end-multi-column
## 延迟消息的实现

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-tips
title: 只有RocketMQ支持延时消息

- 一些方式在RabbitMQ和Kafka上实现延时消息
~~~

</br>

~~~ad-one
title: RabbitMQ

- 利用rabbitmq的<mark class="hltr-blue">ttl</mark>功能, ttl是设置在队列级别上的, 即某个队列消息多久丢弃到死信队列
- 新建一个delay_queue但是没有消费者, biz_queue作为它的死信队列, 我们来消费死信队列
~~~
![[Pasted image 20240909160730.png|577]]

--- column-break ---

~~~ad-two
title: kafka

- 利用定时任务调度平台, 如『airflow』
- 30分钟后执行定时任务发送到消息队列
- 缺点: 并发不高, 定时任务平台的问题
~~~

</br>

~~~ad-two
title: 分区设置不同延迟时间

- 搞一个『delay_topic』, 不同分区是不同延迟时间, 消费组对应消费者获取到消息后根据消息里面的延迟时间来等待, 之后把消息转发到真实的业务消费者上
- 会有Rebalance的问题, 我们可以采取『暂停』和『重放』功能, 暂停消费还是会拉取poll请求, 但是不会真的拉取到消息, 让kafka认为消息者海活着
- 一致性问题, 『后提交』, 我们先转发消息给biz_topic, 后提交, 因为提交前如果宕机, 重复转发也没问题『幂等』
~~~
![[Pasted image 20240909161303.png|577]]

--- column-break ---

~~~ad-three
title: 利用Mysql

- 高并发是个问题可以使用
- 分区表
- 批量操作
~~~
![[Pasted image 20240909165700.png|577]]

--- end-multi-column

## 消息顺序

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-tips
title: 有序消息

- 我们这里强调的是某个topic内部的有序, 而不是跨topic
- 关于『跨topic』有序要求不同的topic执行顺序, 那么要引入一个协调者调整不同topic的消费
~~~

</br>

~~~ad-list
title: 方案

- 有<mark class="hltr-blue">单分区</mark>和<mark class="hltr-cyan">多分区</mark>解决方案之分
- 
~~~

</br>

~~~ad-two
title: 增加分区引起的消息失序

- 如图, 如果我们增加分区前是在分区1还未完成消费, 增加后id=3发到了分区4直接消费了, 乱序了
- 这里可以在增加分区后新的分区的消费者先等待一段时间, 比如三分钟等待同一ID的其他分区的消息先消费完成
- 没办法彻底解决问题, 但是本身分区增加也不是常见操作, 所以加上监控人工修复处理可以接收
~~~
![[Pasted image 20240909175522.png|577]]

--- column-break ---

~~~ad-one
title: 单一分区

- 一个topic只有一个分区, 那么就是全局有序了
- 缺点就是性能太差, 一个分区那么同一个消费组只会有一个消费者
- 要求全局有序的话只能增加机器性能
- 而业务有序(局部有序)则可以使用异步消费和多分区方案
~~~
![[Pasted image 20240909171957.png|577]]

</br>

~~~ad-one
title: 异步消费

- 消费者拉取消息后, 取模基于业务码, 到不同的内存队列中
~~~
![[Pasted image 20240909173352.png|577]]

--- column-break ---

~~~ad-two
title: 多分区

- 通过计算分区来指定发送分区
- 但是计算分区会有一些问题, 『数据不均匀』, 『增加分区的失序』
~~~
![[Pasted image 20240909173654.png|577]]

</br>

~~~ad-two
title: 数据不均匀

- 借鉴Redis的『槽与槽的分配』, redis是使用16384个槽
- 再通过指定不同的槽的数据分配到不同的分区, 槽与分区的绑定关系可以借用配置中心
~~~
![[Pasted image 20240909175401.png|577]]
--- end-multi-column
## 消息积压

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```
~~~ad-tips
title: 解决方案

- 考虑是『临时积压』还是『永久积压』, 如果是前者, 可以接受等待的话就不处理
- 如果是永久积压那就是消费速率赶不上生产速率, 那么, 增加<mark class="hltr-blue">分区</mark>, 同时<mark class="hltr-cyan">增加消费者</mark>
~~~
![[Pasted image 20240909182416.png|577]]

</br>

~~~ad-one
title: 增加Topic

- 如果不允许增加分区的话, 创建对应topic的更多分区的新topic
- 把老topic的消费完毕停掉, 或者老的topic的消费是直接转发到新的topic
~~~
![[Pasted image 20240909183233.png|577]]

--- column-break ---

~~~ad-two
title: 优化消费者性能

- 要么加钱提升消费者机器性能
- 要么就是优化消费逻辑, 比如有没有避免加锁, io等
~~~
![[Pasted image 20240909183540.png|577]]

</br>

~~~ad-three
title: 消费者降级

- 快慢路径选择快路径
- 是不是可以利用缓存代替实时查询
~~~

</br>

~~~ad-success
title: 聚合消息与批量操作

- 如果消费端可以批量处理, 那就减少消息的发送, 降低负载
- 也可以直接只改造消费者, 消费者一次性拉取100条构造批量处理请求, 最后一次性提交偏移量
- 这种批量消费, 批量提交的方法也可以用于<mark class="hltr-blue">异步消费</mark>
~~~
![[Pasted image 20240909184228.png|577]]

--- column-break ---

~~~ad-one
title: 异步消费

- 拉倒消息开Goroutine去消费
- 会有<mark class="hltr-grey">消息丢失的可能</mark>
~~~
![[Pasted image 20240910105549.png|577]]

</br>

~~~ad-one
title: 消息丢失

- 消费者拿到消息提交后异步执行时, 协程还没处理完就宕机
- 『批量提交』, 获取一批等到全部处理完毕再批量提交这批
- 会有<mark class="hltr-grey">重复消费, 部分失败的可能</mark>
~~~

</br>

~~~ad-one
title: 重复消费 & 部分失败

- 批量提交之前宕机, 部分成功部分失败, 『幂等』
- 部分失败时可以考虑重试, 也可以选择重新发一条新消息回去
~~~
--- end-multi-column
## 消息不丢失

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-tips
title: 分区与broker的隔离

- kafka是在分区上进行主从的, 那么分区的主从尽量分散在不同的broker上隔离
- 所以写入消息时, 可以只写入主分区, 也可以写入主分区后写入一部分从分区, 就是acks
- ``
~~~
![[Pasted image 20240910114744.png|577]]

</br>

~~~ad-one
title: broker的可靠性 - acks

- 0: `fire and forget`, 发送后就不管了
- 1: 主分区写入成功响应成功
- all: 主分区写入成功后, 同步给全部ISR成员
- ISR: 和主分区保持同步的从分区
- 同时还有个参数, `min.insync.replicas = 2`, 可以保证至少ISR = 2, 不足2的话all就失败
~~~
![[Pasted image 20240910120245.png|577]]

</br>

~~~ad-one
title: broker的可靠性 - pageCache刷盘参数

- `log.flush.interval.messages`: 控制多少条消息后强制刷盘
- `log.flush.interval.ms`: 间隔多少毫秒刷盘
- `log.flush.scheduler.interval.ms`: 间隔多少毫秒, 检测数据是否应该刷盘, 配合上一条参数使用, 200ms检查pagecache消息是否已经500ms
- <mark class="hltr-blue">要么定量刷, 要么定时刷</mark>
~~~

--- column-break ---

~~~ad-two
title: 发送者的可靠性 - 可靠消息&最终一致

- 本地事务+本地消息表, 执行完成后立即发送, 发送成功删除消息表
- 发送失败则异步的重试, 设置时间间隔, 重试次数, 超过报警人工介入
~~~
![[Pasted image 20240910141751.png|577]]

</br>

~~~ad-three
title: 消费者的可靠性

- 确保执行完业务逻辑再提交
- 如果异步消费, 批量提交, 注意重复消息和部分成功的问题
~~~

--- column-break ---

~~~ad-ex
title: 亮点方案 - kafka实现消息回查

- 消息回查, 即Rocket的事务消息
- 1, 应用把半消息发送到`topic=look_back_msg`, 包含业务topic, 消息体, 业务类型, 业务ID, 准备状态, 回查接口等
- 2, 回查中间件消费`look_back_msg`把消息存储到数据库
- 3, 应用执行完本地事务, 发送消息到`look_back_msg`, 带上业务类型, ID, 提交状态等, 或者使用回滚状态
- 4, 回查中间件查询消息内容转发到topic上
~~~
![[Pasted image 20240910142427.png|577]]

</br>

~~~ad-ex
title: 回查实现

- 如图, 关键点在于『回查中间件怎么回查应用代码』, 设计成http或者rpc接口可扩展, 由这里业务方来告诉我要不要提交

```http
method: POST
URL: https://.../order/lookback
Body: {
	"biz_type": "order",
	"biz_id": "PO110"
}

{
	"biz_type": "order", 
	"biz_id": "PO110", 
	"status": "commit/rollback"
}
```
~~~

</br>

~~~ad-ex
title: 数据存储

- 保证回查机制的高性能和高可用, 可以使用『分区表』按时间分区
- 或者使用『分库分表』比如按照topic来分库分表
~~~

--- end-multi-column
## 消息重复

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-tips
title: 重复消费的原因

- 基本有两种, 生产者重复发送, 重试发送
- 消费者重复消费, 消费完后没有提交
- 一个原则, 一定要设计成幂等的
~~~

--- column-break ---

~~~ad-one
title: 本地事务插入到唯一索引

- 使用本地事务来保证『插入唯一索引表』和业务操作是原子的
- 最好设计成业务本身操作就是唯一索引而不需要额外的唯一索引表
- 只要事务提交成功, 那么重复消息也会因为唯一索引操作失败直接幂等
- 不过如果不能使用本地事务, 比如说分库分表下, 解决方案会麻烦一些
~~~
![[Pasted image 20240910161446.png|577]]

</br>

~~~ad-one
title: 非本地事务插入到唯一索引

- 无法保证原子性的情况下, 只能保证最终一致性
- 依赖第三方检测, 如『async_task』, 整个分为3步骤
- 1, 数据插入唯一索引, 标记初始化状态, 避免重复处理
- 2, 执行业务操作
- 3, 唯一索引对应的数据改为完成
- 如图第二步成功, 第三部失败的话, 异步检测系统扫描初始化状态的唯一索引表和业务表对照, 业务成功则修改唯一索引表, 业务失败触发重试, <mark class="hltr-cyan">异步检测</mark>
~~~
![[Pasted image 20240910162421.png|577]]

--- column-break ---

~~~ad-two
title: 亮点方案 - 布隆过滤器+Redis+唯一索引

- 『层层削流, 确保达到数据库的流量最小化』
- 首先经过布隆过滤器过滤, 存在假阳性问题
- 利用redis存近期处理过的key, key的过期时间要根据根据重复请求的间隔判断
- 最后是唯一索引冲突来兜底
~~~
![[Pasted image 20240910170612.png|577]]

</br>

~~~ad-two
title: 简化版本

- 当然可以只使用布隆过滤器+唯一索引, 或者redis+唯一索引
- 从优化的角度来看, 也可以使用本地布隆过滤器, 结合负载均衡一致性哈希把同一key发送到同一分区, 然后我们使用本地的
- 同时也可以使用本地内存代替redis
- 如果key本身是数字, 同时也可以使用bitarray, 通过判断某一位是否为1还是0来搞
~~~
![[Pasted image 20240910171745.png|577]]

--- end-multi-column
## kafka的高性能

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-one
title: 分段与索引

- 每个分区有多个段, 每个段可以理解为一个文件, 同一个topic的文件就放在topic命名的目录下
- 段文件使用偏移量来命名, 这样可以通过『二分』快速定位段文件
- 每个段文件都有对应的存储位置索引文件<offset, position>, 和时间索引文件<timestamp, position>
~~~
![[Pasted image 20240910173637.png|577]]

~~~ad-one
title:  

- 要查找test_topic下, 分区为1, 偏移量20000的消息
- 进入test_topic_1的目录, 根据文件名二分找到应该在010031.log文件
- 利用010031.index的内容二分查找, 如果存在索引找到索引项<20000, pos0>, 不存在找到比20000小的最近索引项后往后遍历
- 『topic+分区定位目录』, 『偏移量定位文件』, 『索引定位位置』
~~~

--- column-break ---

~~~ad-two
title: 零拷贝

- 中间件泛用技术, 极大提高性能, 所谓零拷贝即没有CPU参与的拷贝
- DMA: 独立于cpu的硬件, NIC: 指网卡
- 1, 应用进入内核, 内核从磁盘读取缓存(DMA)
- 2, 读缓存的数据通过CPU拷贝到应用缓存, 切回用户态
- 3, 应用进入内核, 把缓存CPU拷贝到写缓存, 切换内核态
- 4, 应用把数据从写缓存拷贝到NIC缓存, 这一步是发一个指令, DMA执行
~~~
![[Pasted image 20240910174713.png|577]]

</br>

~~~ad-two
title:  

- 优化方式就是零拷贝, 不经过应用缓存, 直接让磁盘读内核缓存, 内核缓存直接写NIC缓存
- 内核切换只有2次, 少了两次CPU拷贝
- 首先应用程序发起系统调用, 系统调用读取磁盘数据到内核缓存(DMA), 从内核缓存拷贝到NIC缓存(DMA), 没有CPU参与
- 这里说的内核缓存就是『Page Cache』
~~~
![[Pasted image 20240910175514.png|577]]

--- column-break ---

~~~ad-three
title: 批量处理

- 减少系统调用, 内核切换, 网络传输的头部分
- kafka客户端不是一次只发送一条, 而是batch操作, 在broker端存储也是批量的
- 批量的兜底: 固定时间内没凑够批次也会直接发送`linger.ms`
~~~

</br>

~~~ad-three
title: 压缩

- 进一步降低网络传输和存储压力, 对消息进行了端到端压缩, broker存储的压缩后的数据, 消费者解压缩
~~~

</br>

~~~ad-three
title: 分区本身带来的性能

- 并发竞争的粒度缩小到分区上, 不同分区不需要并发控制
~~~

</br>

~~~ad-two
title: PageCache

- kafka充分利用PageCache, 写入的时候几乎等价内存操作异步刷盘
- kafka基于JVM, 利用pagecache能缓解垃圾回收的压力
~~~

</br>

~~~ad-two
title: 顺序写

- 针对每一个分区, 有一个日志文件来WAL, 追加顺序写
- 机械硬盘的顺序写也不比固态硬盘的慢多少, 所以考虑成本, 写入操作可能不太吃硬件
~~~

</br>

~~~ad-two
title: 分区多对写入性能影响

- 每个分区是一个日志文件, 如果100个分区要写入100M, 每个文件写入1M性能差
~~~

</br>

~~~ad-two
title: 分区过多怎么办

- 可以直接不使用一部分分区, 发到指定的分区
- topic过多考虑合并topic, 在消息中使用type来区分子业务
~~~

--- end-multi-column
## 性能优化

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-one
title: 优化生产者 - acks

- 没有严格的消息不丢失要求设置成0, 发送后就不管
- 或者设置成1, 主节点落盘后ack, 严格要求可靠性的话还是all
~~~

</br>

~~~ad-one
title: 优化生产者 - 优化批次

- 『调大批次』, `linger.ms和batch.size`, 前者是凑够批次的最大等待时间, 后者是批次的最大字节数
- broker处理的过来的情况下, 批次越大吞吐量越好
- 可能会影响实时在线性能
~~~

</br>

~~~ad-one
title: 启用压缩

- 消息压缩也可以提升吞吐量
~~~

--- column-break ---

~~~ad-two
title: Broker优化 - 优化swap

- `vm.swappniess`调小可以优化内存, 减少内存的swap, 10或者1
- 物理内存不够用的话使用交换区也比系统不可用强
~~~

</br>

~~~ad-two
title: 优化网络读写缓冲区

- kafka作为网络IO频繁的应用, 调整网络有关的读写缓冲区参数大概6个
- `net.core.rmem_default/net.core.wmem_default`: Socket默认读写缓冲区大小
- `net.core.rmem_max/net.core.wmem_max`: Socket最大读写缓冲区
- `net.ipv4.tcp_wmem/net.ipv4.tcp_rmem`: TCP读写缓冲区, 4k, 64k, 2m
~~~

</br>

~~~ad-two
title: 优化磁盘IO

- 作为一个磁盘IO密集应用
- 相比EXT4, XFS读写性能更好, 禁用一些比如atime(最后访问时间)kafka用不上的
~~~

--- column-break ---

~~~ad-three
title: 优化主从同步

- `num.replica.fetchers`: 从分区拉取数据的线程数量, 默认1, 调成3
- `replica.fetch.min.bytes`: 避免小批量的同步数据
- `replica.fetch.max.bytes`: 调大到5m
- `replica.fetch.wait.max.ms`: 数据不够时从分区的等待时间
- 调整从分区同步线程数量加快同步速率, 调整最小最大批次的大小, 调大等待时间, 值越大吞吐量越高
~~~
![[Pasted image 20240911160254.png|577]]

</br>

~~~ad-three
title: 优化JVM

- 考虑优化JVM, 比如调大JVM的堆内存, 换用G1垃圾回收器等
~~~

--- end-multi-column
