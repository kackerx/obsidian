## ov
--- start-multi-column: In'qhi d_2cos
```column-settings
Number of Columns: 2
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title: 三层消息架构

- 第一层主题层(topic): 每个topic分为M个Partition, 每个Partitioning可以配置N个副本
- 第二层分区层(Partitioning): 每个分区的N个副本有一个Leader副本多个Follower副本, 客户端只和Leader交互, Follower只用作冗余, 分区就相当于Sharding, Region等, 分区自身有Replication
- 第三层消息层(message): 每个分区包含不同的消息, offset从0开始递增
~~~

</br>

~~~ad-grey
title:  

- 其实分区就是为了实现系统的高伸缩性(Scalability), 不同分区分散到不同节点的broker, 可以通过添加新的节点机器增加吞吐量
~~~
![[Pasted image 20240829115404.png|577]]


--- column-break ---



--- end-multi-column
## 分区策略

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 2
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title: 分区策略 - 轮询(Round-robin)

- 默认的分区策略, 保证消息最大限度平均分配到所有分区上, 常用
~~~
![[Pasted image 20240829120210.png|577]]
~~~ad-grey
title: 分区策略 - 随机(Randomness)

- 本质也是想均匀分配, 老版本的默认策略
~~~
![[Pasted image 20240829120405.png|577]]

--- column-break ---

~~~ad-success
title: 按消息键保存策略 - (Key-ordering)

- Kafka允许为每个消息定义消息键(Key), 可以是明确的业务code, id, 或时间戳
- 相同Key的消息进入到同一个Partitioning, 每个Partitioning下的消息处理是有序的
- `hash(key) & len(partitions)`
~~~
![[Pasted image 20240829120544.png|577]]

--- end-multi-column
## 消息丢失
--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title:  

- <mark class="hltr-blue">Kafka只对『已提交』的消息做有限度的持久化保证</mark>, 已提交即是说若干个Broker成功接收到一条并写入日志文件
~~~

</br>

~~~ad-grey
title: 生产者数据丢失

- 生产者发送消息是异步的, 即『fire and forget』, 所以遇到网络抖动, 报错, 生产者是不知道的, 
- 所以要使用带回调通知的API, `producer.Send(msg, callback)`, 在callbask中处理失败情况
~~~

--- column-break ---

~~~ad-success
title: 消费者数据丢失

- 1, 消费者端要保证<mark class="hltr-cyan">维持先消费消息(读), 再更新offset(书签)</mark>, 最大限度保证不丢
- 2, 协程异步消费, 消费者不能开启自动提交offset, 需要应用手动提交
~~~
![[Pasted image 20240829143815.png|577]]

--- column-break ---

~~~ad-warn
title: 最佳实践

1. 使用带`callbask`的发送API
2. 设置`acks = all`, 这是对『已提交』消息的定义, 即要全部的broker都收到才算已提交的最高等级定义
3. 设置`retries`为较大值, 避免网络抖动
4. `unclean.leader.election.enable = false`, Broker的参数控制哪些Broker有资格竞选分区的leader, 如果一个Broker落后进度太多成为新的leader会丢失
5. `replication.factor >= 3`, Broker的参数, 消息的复制集, 冗余
6. `min.insync.replicas > 1`, Broker的参数, 消息最少要写入多少个副本才算
7. `enable.auto.commit = false`, 并采用手动提交offset, 对于单个Consumer多协程处理场景重要
~~~

--- end-multi-column
## 幂等生产者 & 事务生产者

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title: 消费交付可靠性保证

- Kafka对Producer和Consumer要处理的消息提供什么样的承诺
	- 1, 最多一次(at most once): 消息可能丢失, 但不会重复发送(不重试)
	- 2, 至少一次(at least once): 消息不会丢失, 但可能重复发送(网络抖动Producer重试), 默认!
	- 3, 精确一次(exactly once): 消息不会丢失, 也不会重复发送
~~~

--- column-break ---

~~~ad-grey
title: 幂等生产者

- `props.put("enable.idempotence", true)`: 该设置使Producer升级为幂等生产者
- Producer发送了相同字段值的消息后Broker会自动去重
- 幂等生产者仅能保证『某个主题的一个分区』上不重复, 无法实现多个分区的去重
~~~

--- column-break ---

~~~ad-success
title: 事务生产者

- ACID保障

```go
producer.beginTrans()
...commit()
...abort()
```
~~~

--- end-multi-column
## 消费组

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title:  

- 理想情况, 消费组的Consumer实例数量 = 该Group全部订阅主题的分区总数
- 如Group订阅了3个主题, 分别有1, 2, 3分区数, 那么为该Group设置6个Consumer理想
- 右图分别是, 一个消费组只有一个消费者, 2负载均衡, 3满负载, 4空闲一个
~~~

--- column-break ---

![[Pasted image 20221116162547.png|555]]

![[Pasted image 20221116162754.png|555]]


--- column-break ---


![[Pasted image 20221116162903.png|555]]

![[Pasted image 20221116163002.png|555]]
--- end-multi-column
## Rebalance

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title:  

- Rebalance本质上是一种协议, 规定了一个Consumer Group下所有Consumer如何达成一致来分配订阅Topic的每个分区
- 如1个group20个consumer, 定语一个100个patition的topic, 正常情况每个consumer分配5个分区
- 触发重平衡的3个条件
	1. 组成员数变更
	2. 组订阅主题数变更
	3. 订阅主题的分区数变更, Kafka只能增加分区, 增加时订阅该主题的所有Group开启Rebalance
~~~

</br>

~~~ad-danger
title: rebalance的问题

- 参与rebalance的所有Consumer实例都会停止消费等待完成
- 所有Consumer都要参与重新分配, 改动也比较大
~~~

--- column-break ---

~~~ad-grey
title:  

- 比如增加消费者的情况, 如图, 2个分别消费三个分区, 3个分别消费两个分区
~~~
![[Pasted image 20240829171007.png|577]]

--- column-break ---



--- end-multi-column
## 位移提交

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title:  

- Consumer需要向Kafka的每个消费的分区去提交位移(Committing Offsets), 记录自己消费的位置
- 从用户角度, 位移提交分为手动和自动, 从Consumer端角度分为同步和异步
- 
~~~

</br>

~~~ad-warn
title: 手动提交

- 消息的提交由程序控制, `commitSync()`, 注意调用时机避免丢失消息, 调用失败会重试
- 也可以异步`commitAsync()`, 异步提交失败不重试, 因为可能重试时提交的已经不是最新的offset
~~~

--- column-break ---

~~~ad-grey
title: 自动提交

- 自动提交, Kafka Consumer在后端默默为你提交位移, 用户不需关心(默认)
- `auto.commit.interval.ms = 5s`, 5s提交一次
- 自动提交Kafka会保证在开始调用poll方法时, 提交上次poll返回的消息, 顺序上来说poll方法获取记录时提交上一批消息的位移, 因为不会丢失, 但会重复
- 比如设置5s一次自动提交, 假设3s的时候发生了Rebalance, 之后从上次提交的位移处继续消费, 那么这3s消费的还未提交的会重复消费

```go
while (true) {
	 ConsumerRecords<String, String> records = consumer.poll(100);
	 for (ConsumerRecord<String, String> record : records)
		 System.out.printf("offset = %d, key = %s, value = %s%n", record.offset(), record.key(), record.value());
}
```
~~~

--- column-break ---



--- end-multi-column
## Offsets Topic

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 2
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title: 位移主题 - __consumer_offsets

- 是kafka内部的一个主题, 保存消费者的位移信息
~~~

</br>

~~~ad-grey
title: 该主题的消费格式 

- Key: <Group ID，主题名，分区号>, Value: 消息体就是保存了位移值, 时间戳, 等一些元数据
~~~

--- column-break ---

--- end-multi-column
## Partition

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 2
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title:  

- Topic有N个Partition, 集群有N+M个Broker, 那么N个Broker每个节点存储该Topic的一个Partition (broker > partition)
- N个Partition, Broker < N, 那么会有Broker存储多余一个Partition
- Topic只是逻辑概念, 真正分布式的是Partition
- 所以当Partition数量 < Broker时, Partition数越大吞吐越高, 线性提升
~~~
![[Pasted image 20221116143921.png|500]]

--- column-break ---



--- end-multi-column

## 物理存储

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title: 原理

- 运用到『顺序I/O』和『Page Cache』实现高吞吐高性能写入
~~~
![[Pasted image 20221116150831.png|577]]

--- column-break ---

![[Pasted image 20221116150909.png|577]]

--- column-break ---

![[Pasted image 20221116151014.png|577]]

--- end-multi-column

## Kafka高性能IO

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title: 批量处理 

- kafka的生产和发送其实都是批量处理的
- 每次调用`send()`, Kafka其实不会立刻发出去而是缓存在内存, 组批发给Broker
~~~

--- column-break ---

~~~ad-grey
title: 顺序读写

- 顺序读写log文件避免寻址
- 同时利用<mark class="hltr-blue">PageCache</mark>
~~~

--- column-break ---

~~~ad-success
title: ZeroCopy - 零拷贝

- 
~~~

--- end-multi-column
