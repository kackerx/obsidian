## RocketMQ
--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title:  

- 主从节点通过Raft来同步和选举
- 主从节点都要同步到NS, 每台NS是有全部集群路由信息
- 系统从NS获取broker路由
~~~
![[Pasted image 20240724190555.png|577]]

--- column-break ---

~~~ad-success
title:  

- Topic是逻辑概念, 事实上同一个Topic消息会分布式存储到不同的broker上
~~~
![[Pasted image 20240724182516.png|577]]

--- column-break ---

~~~ad-warn
title: 整体工作流

- Broker启动向NameServer注册, 保持长连接, 30s一次心跳
- Producer发送消息时, 从Ns获取Broker地址, 负载均衡算法选择发送
- Consumer消费消息时, 从Ns获取Broker地址, 拉取消息消费
~~~
![[Pasted image 20240903143855.png|577]]

--- end-multi-column
## 发送方式

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title: 发送方式

- 同步, 异步, 单向(不管结果)
~~~
![[Pasted image 20240724185508.png|577]]

--- column-break ---

~~~ad-grey
title: 消费模式

- Push: 由broker主动push给消费者, consumer监听后回调
- Pull: 由消费者for {}去broker拉取
- 其实我觉得可以理解, Push是异步的(注册回调函数, 失败自动重试), Pull是同步的使用for {}不停地拉取
~~~

--- column-break ---

~~~ad-tips
title:  

- 生产者从ns拉取topic的路由数据获取topic的队列
- topic的数据在队列里, 队列分布在不同的broker上(数据分布式分片机制)
~~~
![[Pasted image 20240725104953.png|577]]

--- end-multi-column

## 消息消费

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title:  

- 订阅一个Topic的多个消费组都可以获取到同样的一条生产的消息
- 对于消费组中多个消费者是一个获取到还是组内每个消费者都获取到就是: 集群模式消费 & 广播模式消费
- 通常原则是一个Topic的多个MQ均匀分摊给消费组内的多个机器, 一个MQ被一个消费机器节点消费, 但是一个消费机器负责多个MQ的消费
~~~
![[Pasted image 20240725120812.png|577]]

</br>

~~~ad-ex
title: 消费方式

- 支持PUSH和PULL两种消费方式, 支持集群消费和广播消费
- PULL: 拉取型消费, 主动从服务器拉取信息, 批量获取, 主动型消费
- PUSH: 推送型消费, 用户实现消息到达时的回调接口, 被动型消费
~~~

--- column-break ---

~~~ad-success
title:  

- 消费消息的本质: 根据要消费的mq以及开始消费的位置, 找对应的ConsumeQueue中CommitLog的物理offset
- 处理完一批消息后, 消费者机器提交消费进度给broker, broker存储消费进度
~~~
![[Pasted image 20240725141120.png|577]]

--- column-break ---

~~~ad-warn
title: rebalance

- 负载重平衡: 消费组内的机器宕机, 或者扩容, 触发负载重平衡
~~~

</br>

~~~ad-danger
title: 从master还是从slave拉取

- 从master拉取时, 要读取的CommitLog较新的在OS.Cache中, 较老的消息已经刷入磁盘
- 如果master积压了很多消息, 判断你消费者的进度太慢了未及时跟上生产的进度, 你再从master读大概率读磁盘而非cache
- 此时master判断broker负载高, 会让你去slave读
~~~

--- end-multi-column

## 事务消息

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title:  

- 为了保证mq, 网络, 等任一环节有问题消息就发不出去! 结合补偿机制
- half消息发出去, 响应没收到, 本地事务回滚, mq补偿回调该half对应的事务是commit还是rollback
- half消息发出去, 收到响应, 本地事务执行失败回滚, 同上
- half消息发出去, 收到响应, 本地事务成功, 发送commit给mq, 该commit请求失败也会由mq补偿回调
- 保证本地系统生产者到MQ之间消息不会丢失!
~~~
![[Pasted image 20240725153956.png|577]]

--- column-break ---

~~~ad-bug
title:  

- half并不会发送的对应topic的ConsumeQueue而是发送到内部的『RMQ_SYS_TRANS_HALF_TOPIC』, 所以消费者看不到
- mq后台定时任务扫描事务状态, 然后根据一个op操作标记rollback/commit
- commit后会发送到正确的ConsumeQueue让消费者获取到
~~~

--- end-multi-column
### 有必要一定使用事务消息保证消息不丢失和一致性吗?
--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title: 能不能基于重试机制保证消息发送成功

- 其实通常场景比如kafka也是会通过同步发送+重试机制+幂等保证消息发送成功的, 如下两种情况

</br>

1. 事务提交后, 发送消息和重试
2. 本地事务和发送重试放到同一事务中
~~~

</br>

~~~ad-inf
title: 最佳方案

- 所以最佳方案还是RocketMQ的事务消息
- 保证本地事务成功一定投递消息成功
- half消息发送失败, 或后续rollback和commit发送失败不需要自己重试
- MQ后自动补偿回调
~~~

--- column-break ---

~~~ad-grey
title: 先执行完事务提交, 后发消息和重试

- 如果事务执行成功后宕机, 还没来及发送消息和重试
~~~
![[Pasted image 20240725160137.png|577]]

--- column-break ---

~~~ad-danger
title: 本地事务和发送重试放到同一事务中

- 重试和发送放到事务中, 接口性能问题, 超时异常
- 如果事务包含redis, es等操作, 很难回滚
~~~
![[Pasted image 20240725160639.png|577]]

--- end-multi-column
### 事务消息就一定不会丢失吗
--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 2
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title:  

- 消息如果是在OS.Cache还未刷盘, 此时宕机也可能丢失(异步)
- 已经刷盘还未消费时, 磁盘宕机
- 明确前提: 保证消息写入MQ不代表不丢失
~~~

--- column-break ---

~~~ad-success
title:  

- 第一种情况, 异步刷盘改成同步刷盘, flushDiskType=ASYNC_FLUSH, SYNC_FLUSH
- 第二种磁盘宕机, 采用主从架构同步数据
~~~

--- end-multi-column

## 延时消息

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 2
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title:  

- <mark class="hltr-blue">临时存储</mark>+<mark class="hltr-cyan">定时任务</mark>来实现
- broker收到延时消息, 发送到主题『SCHEDULE_TOPIC_XXXX』相应时间段(固定延时级别), 定时任务来轮询队列, 到期时发送到目标Topic
~~~

--- column-break ---

![[Pasted image 20240903143344.png|577]]

--- end-multi-column
## 消息可靠性/不丢失

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title: 生产阶段

- 要想保证消息的生产阶段不丢失
- 1, 同步发送时, 注意响应结果, 相应失败或者异常要重试
- 2, 异步发送, 要在回调函数中检查结果是否充实
- 3, 超时也可以通过查询日志API检查是否存储成功
~~~
![[Pasted image 20240903142007.png|577]]

--- column-break ---

~~~ad-grey
title: 存储阶段

- 保证消息持久化到<mark class="hltr-blue">CommitLog</mark>中, 即完成刷盘
- 如果选择同步刷盘可以保证不只是pageCache, 关机也没问题
- 主从模式的同步复制和异步复制的高可用
~~~

</br>

~~~ad-success
title: 消费阶段

- 执行完业务逻辑后再ACK
~~~

--- end-multi-column
## 重复消费

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 2
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title: 避免发送时重复

- 通过mq查是否存在消息(性能低没必要)
- 通过redis发送时去重, 可能漏去重(redis故障)
~~~

--- column-break ---

~~~ad-grey
title: 避免消费时重复

- 消费者幂等, 通过状态, db记录等
~~~

--- end-multi-column
## 消费乱序

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primk'j'jary
title: 问题原因

- 同一个Topic消费发送到不同的MQ
- 消费组内不同的消费者消费不同的MQ, 没保证顺序
~~~

--- column-break ---

~~~ad-success
title: 局部有序, partition级别

- 让同实体比如订单处理消息进入同一MQ, 比如<mark class="hltr-blue">code % len(mq)</mark>
- Hash(key)
- 同时有序消息也不能重试, 重试可能打乱执行顺序, 执行失败直接返回`consumer.SuspendCurrentQueueAMoment`
- go注意不要用协程去消费
~~~

--- column-break ---

~~~ad-danger
title: 全局有序

- 生产和消费和队列都是一个
~~~
![[Pasted image 20240903143047.png|577]]

--- end-multi-column
## some others

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 2
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title:  

- 给消息加tags来在消费端有效过滤数据
- 给消息setKey()来有效查询某消息(是否丢失)
- 如果mq集群故障考虑写入消息到db或者文件
- 增加MQ数量和对应的consumer节点, 前者4个后者5个会有一个consumer空闲
- 增加consumer的gorouine, 设置每次批量获取更多消息
~~~

--- column-break ---



--- end-multi-column

## 持久化机制

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title:  

- $HOME/store/consumequeue/TopicXX/MessageQueue0/ConsumeQueue0: 磁盘文件
- topic的多个mq是分散在不同的broker上的, 每个mq对应一个ConsumeQueue文件记录了commitLog的offset
- ConsumeQueue0文件存储的是提交日志CommitLog的消息偏移量offset, 可以看做是基于topic的CommitLog索引文件
- 利用了OS的PageCache异步刷盘, 有丢失数据风险, 吞吐量大
~~~
![[Pasted image 20240725114414.png|577]]

--- column-break ---

~~~ad-grey
title:  

- 主要有『CommitLog, ConsumeQueue, Indexfile』三个文件
- 1, CommitLog: 消息存储文件, 单个文件大小1g, 文件名为20位的起始偏移量, 顺序写入
~~~
![[Pasted image 20240903145426.png|577]]

--- column-break ---

~~~ad-tips
title: ConsumeQueue

- 2, ConsumeQueue: 消息消费队列, 基于topic的CommitLog索引文件, 文件组织形式如图
~~~
![[Pasted image 20240903145656.png|577]]

</br>

~~~ad-bug
title: IndexFile

- 提供一种可以通过key或时间区间来查询消息的方法, HashMap结构
~~~
![[Pasted image 20240903150042.png|577]]

--- end-multi-column
