## ov
--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title:  

- dict: 两个哈希表ht[2], ht[1]用来rehash
- dictht: 哈希表, 元素指向dictEntity
- dictEntity: 节点, 每个value是redisObject
~~~

</br>

~~~ad-one
title: redisObj

- type: 标识对象是String, List, Hash, Set, Zset
- encoding: 标识使用了哪种底层数据结构
- ptr: 指向底层数据结构的指针
~~~
![[Pasted image 20240729105816.png|577]]

--- column-break ---

![[Pasted image 20240729105856.png|577]]

--- column-break ---

![[Pasted image 20240801154007.png|577]]

--- end-multi-column

## SDS

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title:

- len: 字符串长度, 获取长度O(1)
- alloc: 分配给字符数据的空间长度, 修改字符串时通过`alloc - len`, 计算出空间大小
- flags: 区分不同种类的sds, sdshdr5, sdshdr8, sdshdr16, sdshdr32, sdshdr64
- buf[]: 字节数组, 保存字符串和二进制数据
~~~
![[Pasted image 20240801155556.png|377]]

--- column-break ---

~~~ad-grey
title: 节省内存空间

- 不同的sds类型是为了节省内存空间
- 如右图, 常规的结构体char+int会因为『内存对齐』空出来浪费的三个字节
- `__attribute__ ((packed))`会实际占用, 不同的sds类型结构体占用少一点空间
~~~
![[Pasted image 20240801173138.png|577]]

--- column-break ---

![[Pasted image 20240801173316.png]]

![[Pasted image 20240801173334.png]]

--- end-multi-column

## 链表

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 2
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title:  

- 
~~~
![[Pasted image 20240801174010.png|577]]

--- column-break ---

~~~ad-grey
title: 优势&缺陷

- head, len, tail: 双向链表可以快速找到头和尾, 和长度
- 保存一个节点也需要一个链表结构头的分配, 内存开销
- 链表节点内存不连续, 『无法很好的利用cpu缓存』来加速
- 所以3.0之前会用压缩列表, 3.2之后用quicklist替换
~~~

--- end-multi-column

## 压缩列表

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title:  

- 为了节约内存而开发, 由连续内存块组成的顺序型数据结构, 类似数组
- zlbytes: 记录整个压缩列表占用对, 内存字节数
- zltail: 列表尾的偏移量
- zllen: 列表节点数量
- zlend: 标记列表的结束点(0xFF)十进制255
- prevlen: 记录『前一个节点长度』
- encoding: 节点实际数据的『类型和长度』, 类型主要有[字符串|整数]
- data: 当前节点实际数据, 类型和长度由『encoding』决定
- 
~~~

</br>

~~~ad-grey
title:  

- 压缩列表找第一个和最后一个可以直接定位O(1), 其他元素需要遍历就是O(N)了
- 因为和数组相比, 每个节点大小是不一样的, 所以只适合少数据
~~~
![[Pasted image 20240801175047.png|577]]

--- column-break ---

~~~ad-success
title:  

- 对于prevlen, 前一个节点长度<254, prevlen属性用1个字节, 否则用5个字节保存
- 对于encoding如图, 节点数据是整数, 长度占1字节, 通过encoding确定了具体整数类型后, 就可以确定实际数据的实际大小了
- 节点数据是字符串, 根据字符串长度, encoding使用『1/2/5』字节的空间编码, encoding前两个bit表示数据的类型`embstr|raw`, 后续其他bit位表示实际数据content长度
~~~
![[Pasted image 20240801180952.png|577]]

--- column-break ---

~~~ad-warn
title: 连锁更新 

- 每个节点的prevlen保存前一个节点的大小, 需要用1个字节
- 此时新来个头长度超过254, e1的prevlen需要用5个字节来保存, e1可能超过254, 导致e2也要扩展...
~~~

</br>

~~~ad-danger
title: 缺陷

- 连锁更新发生导致内存空间多次重新分配, 影响访问性能
- 除首尾外, 访问需要遍历
- 只适用于保存节点数量不多的场景
~~~
![[Pasted image 20240801182025.png|577]]

--- end-multi-column

## 哈希表

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title:  

- dictEntity包含key, value外, 还有next指向桶中下一个, 链式哈希解决冲突
- ht[1]用来进行rehash
~~~
![[Pasted image 20240801183735.png|577]]

--- column-break ---

~~~ad-inf
title: 渐进式rehash

- 通常哈希表2分配2倍的空间
- rehash期间, 每次对哈希表crud会将源表中索引位置上的所有k-v迁移到表2, 避免一次性rehash的耗时操作
- rehash期间有两个表, 所以删除, 查找, 更新操作会在两个表中进行
- 新增只在表2, 保证了表1的k-v数量逐渐减少, 直到rehash完成, 表1变成空表
~~~

</br>

~~~ad-note
title: 触发条件

- 负载因子 = 节点数量 / 表大小
- 负载因子>1, 没有执行bgsave和bgrewriteaof操作
- 负载因子>5, 强制rehash
~~~

--- column-break ---

![[Pasted image 20240801184122.png|577]]

--- end-multi-column

## 整数集合

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 2
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title:  

- encoding决定contents整数数组中每个元素的大小
- 整数集合的升级操作如图
- 原数组上扩容, 然后升级每个元素的大小
~~~
![[Pasted image 20240802110612.png|577]]

--- column-break ---

![[Pasted image 20240802110546.png|577]]

--- end-multi-column
## 跳表

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 3
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-danger
title:  

- 只有Zset对象底层用了跳表, 支持平均O(logN)复杂度的查找
- 数据结构中同时使用了哈希表+跳表, 更新和插入同时进行, 同时保证了范围查询和高效的单点查询
~~~
![[Pasted image 20240802111040.png|577]]

![[Pasted image 20240802112308.png|577]]

![[Pasted image 20240802112839.png|577]]

--- column-break ---

~~~ad-primary
title:  

- 头结点的L0层有12345, L1层有235, L2层有3
- 如果要找到4, 只需要L2 -> 3 --> 4
- 跨度span, level[], 等级数组中, 包含了指向下一节点和对应的跨度
~~~

</br>

~~~ad-grey
title: 跳表的查询

- 从头结点最高层开始, 逐一遍历每层, 根据节点的sds元素和score权重来判断
- 如果节点权重『小于』要查找的权重, 访问该层的下一个节点
- 如果节点权重『等于』要查找的权重, 根据节点的sds『小于』要查找的数据时, 访问该层的下一个节点
- 两个条件不满足或下一个节点为空, 访问节点的level数组的下一层指针, 相当于跳到下一层
~~~

</br>

~~~ad-success
title:  

- 如图要找元素: (abcd, 4)
- 头结点从L2开始找到(abc, 3), 比较权重<4, 访问下一层, 下一层是null, 访问leve[1]
- leve[1]指向(abcde, 4), 权重相同, 但sds大于, 跳到leve[0]
- 找到leve[0] --> (abcd, 4)
~~~
![[Pasted image 20240802113304.png|577]]

--- end-multi-column

## quicklist

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 2
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title:  

- 链表最先由双向链表+压缩列表实现, 当前由quicklist实现
- quicklist = 双向链表 + 压缩列表, quicklist本身是个链表, 每个节点都是一个压缩列表
- 压缩列表通过紧凑的内存布局节省内存, 但是元素增加或者变大, 会有『连锁更新』风险
- quicklist: 控制每个链表节点中压缩列表的大小或者个数来规避连锁更新的问题
- 
~~~
![[Pasted image 20240802115909.png|577]]

--- column-break ---

~~~ad-primary
title:  

- 添加一个元素时检查插入位置的压缩列表是否能容纳下该元素
- 不能容纳才会新建quickListNode结构
- quickList控制节点的压缩列表的大小和元素个数, 规避潜在的连锁更新风险
~~~
![[Pasted image 20240802120048.png|577]]

--- end-multi-column

## listpack

--- start-multi-column: ID_2cos
```column-settings
Number of Columns: 2
Largest Column: standard
Border: off
Shadow: off
```

~~~ad-primary
title:  

- encoding: 该元素的编码类型, 不同长度的整数和字符串进行编码
- data: 实际数据
- len: encoding+data的总长度
~~~

</br>

~~~ad-grey
title:  

- 目的是替代压缩列表, 避免连锁更新问题, 每个节点不再包含前一个节点长度
- 同样采用压缩列表的紧凑内存排列的结构
- 因为只记录当前节点的len, 不记录前一个节点的长度, 所以不会影响其他节点的长度字段变化
~~~
![[Pasted image 20240802120852.png|577]]

--- column-break ---

~~~ad-danger
title: 为什么压缩列表的entry需要保存prevlen, listpack改成len没问题?

- 压缩列表是为了实现节点从后往前遍历, 知道前一个节点的长度就可以计算前一个节点的偏移量
~~~

--- end-multi-column
