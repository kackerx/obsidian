# Scheduler

:::::::::::::::::::::::::::::::::::::::: {.columns shadow=off border=off col-count=2 largest-column=firs}

~~~ad-primary
title:  

k8s的调度器核心就是两个相互独立的控制循环

1. Informer Path: 启动一系列informer来watch etch中的Pod, Node, Service等与调度相关的API对象变化, 负责入队优先级队列和维护缓存数据
2. Scheduling Path: 从队列获取一个pod然后过滤可用node打分, 将pod的nodeName更新为node名即为『bind』, 更新到缓存然后异步goroutine去更新apiserver
3. 最终节点上的kubelet通过Admit的操作二次验证pod是否可运行, 这一步就是GeneralPredicates的最近本调度算法, 比如资源是否可用, 端口是否冲突等
~~~

::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::columnbreak
:::

![[Pasted image 20240115141858.png]]

::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

:::::::::::::::::::::::::::::::::::::::: {.columns border=off col-count=2 largest-column=firs}

![[Pasted image 20231211111813.png|666]]

~~~ad-bug
title:  

1. 第一类型-GeneralPredicate: 基础调度策略如PodFitsResources计算cpu和内存等是否可用, 检查pod的requests字段, GPU等的需要resources.requests.alpha.k8s.io/nvidia-gpu: 2
2. 第二类型-Volume相关规则: NoDiskConflict检查的条件看多个pod挂载的持久Volume是否冲突, VolumeZonePredicate检查持久化volume的zone(高可用域)标签是否匹配
3. 第三类型-Node相关规则: 比如PodToleratesNodeTaints检查Node的『污点』, NodeMemoryPressurePredicate检查节点内存是否充足
4. 第四类型-Pod相关规则: 跟第一类大多重合, 比较特殊的是PodAffinityPredicate, 检查待调度pod和该node上的已存在pod的亲密(affinity)和反亲密(anti-affinity)关系

~~~

::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::columnbreak
:::

![[Pasted image 20231211111053.png|666]]

![[Pasted image 20231211111635.png|666]]


::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
## 亲和性
:::::::::::::::::::::::::::::::::::::::: {.columns border=off col-count=2 largest-column=firs}

![[Pasted image 20231212141333.png|666]]
~~~ad-bug
title:  

- requiredDuringSchedulingIgnoredDuringExecution: 这条规则在pod调度时检查, 如果是已运行的pod, node标签发生变化如Label修改后不适合pod的亲和性条件了, pod依旧继续运行
- topologyKey: 规则有效作用域, 仅对携带某些key的标签的node有效
~~~


::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::columnbreak
:::

![[Pasted image 20231212113457.png|666]]

::::::::::
:::::::::::::::::::::::::::::::::::::::: {.columns shadow=off border=off col-count=2 largest-column=firs}

pod

::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::columnbreak
:::

![[Pasted image 20240228165029.png|777]]

::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
## Taints(node) & Tolerations(pod), 污点和容忍
:::::::::::::::::::::::::::::::::::::::: {.columns border=off col-count=3 largest-column=firs}

> 目前支持的Taint类型, `k taint nodes work1 for-special-user=kacker:NoSchedule`

- <mark class="hltr-pink">NoSchedule</mark>: 新的Pod不调用该Node, 不影响正在运行的pod
- <mark class="hltr-cyan">PreferNoSchedule</mark> : soft版的NoSchedule, 尽量不调度到该Node
- <mark class="hltr-grey">NoExecute</mark>: 新节点不调度到该Node, 并且删除(evict)已在运行的Pod, Pod可以增加一个时间(tolerationSeconds)
---
多租户集群 - 计算资源隔离
- 将要相互隔离的计算节点打上Trants
- 用户创建pod时, 定义tolerations制定要调用到node trants

::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::columnbreak
:::

![[Pasted image 20231212144337.png|666]]


::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::columnbreak
:::

~~~ad-grey
title: tips

1. Equal: 表示容忍的key和value必须与污点完全匹配, effect也匹配才容忍该污点
2. Exist: 表示忽略污点的value, 只要key和effect匹配就容忍, 如果Pod容忍没有指定effect, 那么任何效果的污点都会被容忍, 只要key匹配
~~~

```bash
# 去除master污点
kubectl taint nodes master-node node-role.kubernetes.io/master:NoSchedule-
```

::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
~~~ad-ex
title: tips

### 亲和性（Affinity）


- **目的**：亲和性用于吸引某些 Pod 到特定的节点。它允许您根据节点的属性或其他 Pod 的标签来定义 Pod 应该被调度到哪些节点上。
- **用途**：比如，您可以使用亲和性将相关的 Pod（例如，前端应用和后端数据库）调度到彼此较近的位置，以降低延迟或增加带宽。
- **灵活性**：亲和性规则可以是强制性的（Pod 一定会被调度到符合条件的节点上），也可以是优先级的（调度器会尽量满足条件，但不是绝对）。

### 污点（Taints）和容忍（Tolerations）

- **目的**：污点和容忍用于排斥某些 Pod 从特定节点上运行。它们一起工作，允许节点“排斥”不符合特定规则的 Pod。
- **用途**：例如，您可以为特定的节点添加污点以防止一般的工作负载在上面运行，保留它们用于特定类型的工作负载或管理任务。
- **机制**：如果一个节点有一个污点，只有那些容忍这个污点的 Pod 才能被调度到该节点上。

### 为什么同时需要

1. **互补机制**：亲和性和污点/容忍在概念上是互补的。亲和性是“吸引”机制，用于指示哪些 Pod 应该被调度到特定节点。而污点和容忍是“排斥”机制，用于阻止某些 Pod 被调度到特定节点。
    
2. **灵活性和控制**：这两种机制为集群管理员提供了更多的灵活性和控制能力，使他们能够更精细地管理 Pod 的调度和节点的使用。
    
3. **特殊用途节点**：污点和容忍特别适用于处理需要特殊处理的节点，比如高性能计算、GPU 加速或具有高安全要求的节点。
    
4. **紧急情况处理**：污点还可以用于紧急情况，比如一个节点出现问题时，可以快速地防止新的 Pod 调度到这个节点上。
~~~




